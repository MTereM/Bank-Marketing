{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:08:45.533794Z",
     "start_time": "2020-07-27T10:08:45.518837Z"
    }
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "\n",
    "td {font-size: 14px}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bank Marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is related with direct marketing campaigns (phone calls) of a Portuguese banking institution. The classification goal is to predict if the client will subscribe a term deposit (variable y). The data was downloaded from https://archive.ics.uci.edu/ml/datasets/Bank+Marketing.\n",
    "<br>\n",
    "<br>\n",
    "*Source: [Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014*\n",
    "<br>\n",
    "<br>\n",
    "There are four datasets in this repository:\n",
    "1. bank-additional-full.csv with all examples (41188) and 20 inputs, ordered by date (from May 2008 to November 2010), very close to the data analyzed in [Moro et al., 2014]\n",
    "2. bank-additional.csv with 10% of the examples (4119), randomly selected from 1), and 20 inputs.\n",
    "3. bank-full.csv with all examples and 17 inputs, ordered by date (older version of this dataset with less inputs).\n",
    "4. bank.csv with 10% of the examples and 17 inputs, randomly selected from 3 (older version of this dataset with less inputs)\n",
    "\n",
    "<br>\n",
    "In this project I will use the 'bank-additional-full.csv' dataset.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature description:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Feature | Type | Description |\n",
    "|:---------|:------|:-------------|\n",
    "|*Bank client data*|\n",
    "|age|numeric|age clients|\n",
    "|job|categorical|type of job ('admin', 'blue-colar', 'entrepreneur', 'housemaid', 'management', 'retired', 'self-employed', 'services', 'student', 'technician', 'unemployed', 'unknown')|\n",
    "|marital|categorical|marital statues ('divorced' (divorced or widowed), 'married', 'single', 'unknown')|\n",
    "|education|catgeorical|'basic.4y', 'basic.6y', 'basic.9y', 'high.school', 'illiterate', 'professional.course', 'university.degree', 'unknown'|\n",
    "|default|categorical|has credit in default? ('yes', 'no', 'unknown')|\n",
    "|housing|categorical|has housing loan? ('yes', 'no', 'unknown')|\n",
    "|loan|categorical|has personal loan? ('yes', 'no', 'unknown')|\n",
    "|*Related with the last contact of the current campaign* |\n",
    "|contact|categorical|contact communication type ('cellular', 'telephone')|\n",
    "|month|categorical|last contact month of the year ('jan', 'feb', 'mar', ... ,'nov', 'dec')|\n",
    "|day_of_weel|categorical|last contact day of the week ('mon', 'tue', 'wed', 'thu', 'fri')|\n",
    "|duration|numeric|last contact duration in seconds. Remark: this attributes highly affects the output target (e.g., if duration=0 then y='no'). Yet, the duration is not known before a call is performed. Also, after the end of the call, y is obviously known. Thus, this input should only be included for benchmark purposes and should be discarded if the intention is to have a realistic predictive model.|\n",
    "|*Other attributes*|\n",
    "|campaign|numeric (includes last contact)|number of contacts performed during this campaign and for this client|\n",
    "|pdays|numeric, 999 means client was not previously contacted |number of days that passed by after the client was last contacted from a previous campaign|\n",
    "|previous|numeric|number of contacts performed before this campaign and for this client|\n",
    "|poutcome|categorical|outcome of the previous marketing campaign ('failure', 'nonexistent', 'success')|\n",
    "|*Social and economic context attributes*|\n",
    "|emp.var.rate|numeric| employment variation rate - quaterly indicator|\n",
    "|cons.price.idx| numeric| consumer price index|\n",
    "|cons.conf.idx|numeric| consumer confidence index - monthly indicator|\n",
    "|euribor3m|numeric| euribor 3 month rate - daily indicator|\n",
    "|nr.employed |numeric| number of employees - quaterly indicator|\n",
    "|*Output variable (desired target)*|\n",
    "|y|categorical| has the client subscribed a term deposit? ('yes', 'no')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:08:46.021627Z",
     "start_time": "2020-07-27T10:08:45.536787Z"
    }
   },
   "outputs": [],
   "source": [
    "# general imports\n",
    "from IPython.core.display import display,HTML # for ipywidgets\n",
    "import zipfile # to get data\n",
    "from urllib.request import urlopen # to get data\n",
    "from io import BytesIO # to get data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from display_side_by_side import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:08:48.153336Z",
     "start_time": "2020-07-27T10:08:46.024622Z"
    }
   },
   "outputs": [],
   "source": [
    "# visualizations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Cufflinks\n",
    "import cufflinks as cf\n",
    "cf.go_offline()\n",
    "\n",
    "# Plotly\n",
    "import plotly\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.figure_factory as ff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:08:48.170291Z",
     "start_time": "2020-07-27T10:08:48.155333Z"
    }
   },
   "outputs": [],
   "source": [
    "# user-defined functions\n",
    "from dataset_overview import *\n",
    "from eda_cat_vs_target_binary import *\n",
    "from eda_num_vs_target_binary import *\n",
    "from eda_num_univ_binary import *\n",
    "from cross_tab_chi_sqrt_p_value import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:08:48.177273Z",
     "start_time": "2020-07-27T10:08:48.172287Z"
    }
   },
   "outputs": [],
   "source": [
    "# ipywidgets\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:08:48.947318Z",
     "start_time": "2020-07-27T10:08:48.181264Z"
    }
   },
   "outputs": [],
   "source": [
    "# pandas pipelines\n",
    "import pdpipe as pdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:08:48.954933Z",
     "start_time": "2020-07-27T10:08:48.949945Z"
    }
   },
   "outputs": [],
   "source": [
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:23:12.122174Z",
     "start_time": "2020-07-27T10:23:12.116191Z"
    }
   },
   "outputs": [],
   "source": [
    "#display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to highlight max values in table\n",
    "def highlight_max(data, color='red'):\n",
    "    '''\n",
    "    highlight the maximum in a Series or DataFrame\n",
    "    '''\n",
    "    attr = 'background-color: {}'.format(color)\n",
    "    if data.ndim == 1:  # Series from .apply(axis=0) or axis=1\n",
    "        is_max = data == data.max()\n",
    "        return [attr if v else '' for v in is_max]\n",
    "    else:  # from .apply(axis=None)\n",
    "        is_max = data == data.max().max()\n",
    "        return pd.DataFrame(np.where(is_max, attr, ''),\n",
    "                            index=data.index, columns=data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:08:50.577557Z",
     "start_time": "2020-07-27T10:08:48.961913Z"
    }
   },
   "outputs": [],
   "source": [
    "z = urlopen('http://archive.ics.uci.edu/ml/machine-learning-databases/00222/bank-additional.zip')\n",
    "myzip = zipfile.ZipFile(BytesIO(z.read())).extract('bank-additional/bank-additional-full.csv')\n",
    "data = pd.read_csv(myzip,sep=';')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick look at the data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:08:50.622129Z",
     "start_time": "2020-07-27T10:08:50.580196Z"
    }
   },
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:08:51.334564Z",
     "start_time": "2020-07-27T10:08:50.624079Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_overview(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So in this dataset we have 21 variables and 41188 observations, we don't have missing values, and we have 12 rows (about 0.03%) which are duplicates. From the descriptive statsistics for numerical variables we can see that there are some zeros as min values for the 'duration', 'pdays' and 'previous'. The `duration` is the last contact duration, so if the duration is 0 seconds, there was no last contact. Regarding `pdays`, which is the number of days passed by after the client was last contacted from a previous campaign, if pdays = 0, that means that the client was contacted in the last 24h. Also this variable has a max value of 999 which means that the client was not previously contacted. `previous` represents the number of contacts performed before this campaign and for this client, thus previous = 0 means that the client was never contacted. So the presence of zeros is not weird.\n",
    "<br>\n",
    "We also see some negative values for 'emp.var.rate' and 'cons.conf.idx'. Although I couldn't find how `emp.var.rate` is calculated, I assume that is just a variation in the employment rate on a quartely bases, so a negative number is not weird. For the `cons.conf.idx`, which measures how consumers feel about jobs, the country and spendings, negative values means that consumers pessimistic opinions prevails.\n",
    "<br>\n",
    "<br>\n",
    "Regarding the categorical variables, again we don't have any missing values (null values). \n",
    "<br>\n",
    "Most of the clients:\n",
    "- are admin, married and with a university degree;\n",
    "- do not have credit in default, do not have a personal loan, but do have a housing loan;\n",
    "- were contacted via cellular in may and on thursdays!\n",
    "- the outcome of the previous marketing campaign was mainly 'nonexisting' (new clients?)\n",
    "- didn't subscribe a term deposit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also have a great amout of zeros (about 86.4%) which may be from a specific column. For the rest, regarding data quality, it seems that everything is ok."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason I am going to split the data into a train and test sets at this point of the analysis, it to avoid the so called `data snooping bias`. After all, if the test set is a proxy for new unseen data, then we should not see it anyway.\n",
    "<br>\n",
    "Reference: Hands-On Machine Learning with Scikit-Learn and TensorFlow, Aurélien Géron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the project description we know that we are dealing with a classification task, more precisely a binary classification. And we also know from the descriptive statistics for categorical variables, then the majority of the clients didn't subscribe a term deposit (y = no is 36548 out of 41188). Thus, before splitting the data let's just check how imbalanced the target is so we can maintain the same proportions of the response in the training and test set after splitting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:08:51.365514Z",
     "start_time": "2020-07-27T10:08:51.336551Z"
    }
   },
   "outputs": [],
   "source": [
    "counts = data['y'].value_counts()\n",
    "counts_perc = 100*data['y'].value_counts()/len(data)\n",
    "target_data_proportions = pd.DataFrame({'Target Counts':counts,'Target Counts (%)':counts_perc}).round(2)\n",
    "target_data_proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we have a highly imbalanced dataset, with about 88.73% of the observations belonging to the class no (clients did not subscribed to a term deposit). Thus we need to take this into consideration while splitting the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:08:51.452279Z",
     "start_time": "2020-07-27T10:08:51.368465Z"
    }
   },
   "outputs": [],
   "source": [
    "split = StratifiedShuffleSplit(n_splits=1,test_size=0.2,random_state=123)\n",
    "for train_index,test_index in split.split(data,data['y']):\n",
    "    strat_train_set = data.loc[train_index]\n",
    "    strat_test_set = data.loc[test_index]\n",
    "    \n",
    "# we could use instead train_test_split with stratify and get the same result\n",
    "# train_set, test_set = train_test_split(data,test_size=0.2,stratify=data['y'],random_state=123) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check if the proportions of the response in the train and test sets were mantained:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:08:51.477175Z",
     "start_time": "2020-07-27T10:08:51.454235Z"
    }
   },
   "outputs": [],
   "source": [
    "target_train = strat_train_set['y']\n",
    "target_test = strat_test_set['y']\n",
    "counter_train = Counter(target_train)\n",
    "counter_test = Counter(target_test)\n",
    "\n",
    "print('Train target:')\n",
    "for k_train,v_train in counter_train.items():\n",
    "    perc_train = round(v_train/len(target_train)*100,2)\n",
    "    print('Class={}, Count={}, Percentage={}'.format(k_train,v_train,perc_train))\n",
    "    \n",
    "print('')\n",
    "\n",
    "print('Test target:')\n",
    "for k_test,v_test in counter_test.items():\n",
    "    perc_test = round(v_test/len(target_test)*100,2)\n",
    "    print('Class={}, Count={}, Percentage={}'.format(k_test,v_test,perc_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a training set and a test set where the proportions of the target variable are maintained as they were in the whole dataset, let's proceed to EDA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:08:51.491137Z",
     "start_time": "2020-07-27T10:08:51.481163Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's give another name to the training set\n",
    "df = strat_train_set.copy(deep=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first drop 'duration' due to possible data leakage (see 'Feature description' above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:08:51.508092Z",
     "start_time": "2020-07-27T10:08:51.494129Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df.drop('duration',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check again the dataset stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:08:51.842198Z",
     "start_time": "2020-07-27T10:08:51.514082Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_overview(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By droping the column 'duration' the number of duplicated rows increases greatly. However, since there is no unique ID to identify the clients, I don't think that we can treat these duplicated rows as such. For example, from the table below we have two duplicated rows for clients with 28 years old that are students and single (and ...), but you can have more than one client that is 28 years old and so on. So let's leave these rows like this for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:08:51.913052Z",
     "start_time": "2020-07-27T10:08:51.845192Z"
    }
   },
   "outputs": [],
   "source": [
    "dup = df[df.duplicated(keep=False)]\n",
    "dup.loc[(dup['age']==28) & (dup['job']=='student') & (dup['education']=='basic.9y')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numeric variables Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by analysing each continuous variable (univariate analysis):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:09:00.325240Z",
     "start_time": "2020-07-27T10:08:51.915005Z"
    }
   },
   "outputs": [],
   "source": [
    "print('')\n",
    "print('Figure 1: Numeric Variables Summary')\n",
    "print('')\n",
    "eda_num_univ_binary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Variables|  Observations      |\n",
    "|:---------|:--------|\n",
    "|age|- The clients of this bank have ages that range from 17 to 98 years old.\n",
    "|   |- Median of the clients is 38 years old, and about 75% of clients has an age less than 47 years old.\n",
    "|   |- There appear to exists some outliers. From the boxplot we can see that the extreme values regarding age range from 70 to 98 years old. However, these extreme values in my opinion, are just that! I also don't think that people with a certain age cannot be clients of a bank!| \n",
    "|campaign|- The number of contacts performed during this campaign and for this client ranges from 1 to 43. This variable includes the last contact.\n",
    "|        |- About 75% of the contacts are less than 3. The most frequent number of contacts in this dataset is 1 (43.10%).\n",
    "|        |- ( appears to be a good candidate for discretization)|\n",
    "|pdays|- The great majority of the clients (96.38%) was not contacted previously (pdays = 999,are these new clients?)\n",
    "|     |- (appears to be a good candidate for discretization)|\n",
    "|previous|- 86.37% of the values in this feature are zeros, which means that for the great majority, the number of days passed before the last campaign was zero!\n",
    "|     |- (also a good candidate for dicretization)|\n",
    "|emp.var.rate|- The employment variation rate ranges from -3.4 to 1.4.\n",
    "|            |- 75% of the values are below 1.4.\n",
    "|            |- (good candidate for binning. From the histogram a natural approach would be -inf,-1.8], ]-1.8,-0.1], ]-0.1,+inf )|\n",
    "|cons.price.idx|- The consumer price index ranges from 92.20 to 94.77.\n",
    "|              |- 75% of the values are below 93.994.\n",
    "|              |- (this feature also apears to be more categorical in nature than continuous. Also a good candidate to be discretized)|\n",
    "|cons.conf.idx|- The consumer confidence index ranges from -50.80 to -26.90.\n",
    "|             |- 75% of the values are below -36.4.\n",
    "|             |- (this feature also apears to be more categorical in nature than continuous. Also a good candidate to be discretized)|\n",
    "|euriborm3m|- The euribor 3 month rate ranges from 0.63 to 5.04.\n",
    "|          |- 75% of the values are below 4.961\n",
    "|          |- (appears to be a good candidate for discretization)|\n",
    "|nr.employed|- The number of employees ranges from 4963.60 to 5228.10.\n",
    "|           |- 75% of the values are below 5228.1.\n",
    "|           |- (appears to be a good candidate for discretization)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we look at the numeric features vs the target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:09:07.149995Z",
     "start_time": "2020-07-27T10:09:00.327236Z"
    }
   },
   "outputs": [],
   "source": [
    "print('')\n",
    "print('Figure 2: Numeric Features vs Response Variable Summary')\n",
    "print('')\n",
    "eda_num_vs_target_binary(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|variables| Observations        |\n",
    "|:---------|:---------|\n",
    "|age      |- It appears that most clients that subscribe to a term deposit have ages somewhere between 28 and 38 years old. Regarding the boxplot it does not appear to show a significant difference between the ages of clients that subscribed and clients that didn't. However, it appears that clients that are in the 60+ age group are more likely to subscribe to a term deposit. We can slice the age in bins so we can make the age groups more interpetable. Thus I will slice the age in bins of 10 years.\n",
    "|campaign |-For a number of contacts equal to 1, 49.5% of the clients subscribed to a term deposit, and it appears the more the number of contacts the less subscriptions. Furthermore, calling the clients more than 10 times seems quite a bit!!|\n",
    "|pdays    |-Not much info from the plots. This feature will be encoded and further analysed in the 'categorical data analysis' section.|\n",
    "|previous, emp.var.rate, cons.price.idx, cons.conf.idx, euribor3m and nr.employed|-will also be discretized|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look now at the correlations between numeric variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:09:07.282641Z",
     "start_time": "2020-07-27T10:09:07.151991Z"
    }
   },
   "outputs": [],
   "source": [
    "print('')\n",
    "print('Figure 3: Correlation matrix numeric features')\n",
    "print('')\n",
    "df2 = df.copy()\n",
    "df2['y_num'] = df2['y'].map({'yes':1,'no':0})\n",
    "df_corr = df2.corr()\n",
    "fig = ff.create_annotated_heatmap(\n",
    "    z=df_corr.values,\n",
    "    x=list(df_corr.columns),\n",
    "    y=list(df_corr.index),\n",
    "    annotation_text=df_corr.round(2).values,\n",
    "    showscale=False)\n",
    "fig.update_layout(template='plotly_dark')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlations between the numeric features and the response are very low. However, there are three pairs of correlations above 0.9: r(emp.var.rate,nr.employed) = 0.91, r(emp.var.rate,euribor3m) = 0.97, and r(euribor3m,nr.employed) = 0.95. Let's take a closer look at these features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:09:11.167257Z",
     "start_time": "2020-07-27T10:09:07.284636Z"
    }
   },
   "outputs": [],
   "source": [
    "print('')\n",
    "print('Figure 4: Scatter plot highest correlated features')\n",
    "print('')\n",
    "fig1 = px.scatter(df,x='emp.var.rate',y='nr.employed',render_mode='webgl',trendline='ols',trendline_color_override='yellow')\n",
    "fig2 = px.scatter(df,x='emp.var.rate',y='euribor3m',render_mode='webgl',trendline='ols',trendline_color_override='green')\n",
    "fig3 = px.scatter(df,x='nr.employed',y='euribor3m',render_mode='webgl',trendline='ols',trendline_color_override='orange')\n",
    "\n",
    "trace1 = fig1['data'][0]\n",
    "trace1_trend = fig1['data'][1]\n",
    "trace2 = fig2['data'][0]\n",
    "trace2_trend = fig2['data'][1]\n",
    "trace3 = fig3['data'][0]\n",
    "trace3_trend = fig3['data'][1]\n",
    "\n",
    "\n",
    "fig = make_subplots(rows=1,cols=3,subplot_titles=('r = 0.91','r = 0.97','r = 0.95'))\n",
    "fig.add_trace(trace1,row=1,col=1)\n",
    "fig.add_trace(trace1_trend,row=1,col=1)\n",
    "fig.add_trace(trace2,row=1,col=2)\n",
    "fig.add_trace(trace2_trend,row=1,col=2)\n",
    "fig.add_trace(trace3,row=1,col=3)\n",
    "fig.add_trace(trace3_trend,row=1,col=3)\n",
    "\n",
    "fig['layout']['xaxis']['title']='emp.var.rate'\n",
    "fig['layout']['yaxis']['title']='nr.employed'\n",
    "fig['layout']['xaxis2']['title']='emp.var.rate'\n",
    "fig['layout']['yaxis2']['title']='euribor3m'\n",
    "fig['layout']['xaxis3']['title']='euribor3m'\n",
    "fig['layout']['yaxis3']['title']='nr.employed'\n",
    "\n",
    "fig.update_layout(template='plotly_dark')\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that these correlations are misleading particularly the scatter plots of (emp.var.rate vs euribor3m) and (euribor3m vs nr.employed). This does not appear to be the best representation of this data, not only because the data is packed into columns (emp.var.rate vs euribor3m and euribor3m vs nr.employed), but there are also many overlapping points.The scatter plots again suggests that this data is more categorical in nature than continuous."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical variables Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by discretizing the above mentioned variables with the help of pipelines (since all the transformations made in the train set have to be repeated in the test set):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:09:11.183215Z",
     "start_time": "2020-07-27T10:09:11.172245Z"
    }
   },
   "outputs": [],
   "source": [
    "# copy of df\n",
    "df_cat = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Variables|Categorization|\n",
    "|:---------|:--------------|\n",
    "|campaign |categorized into (one,two,three,more than three), since about 81.6% of the data falls within the first three levels.          |\n",
    "|pdays    |categorized into ('contacted', 'never contacted') where 999 = 'never contacted'.|\n",
    "|previous |categorized into ('contacted', 'never contacted'), where 0 = 'never contacted'.|\n",
    "|emp.var.rate| categorized into (-inf,-1.8],(-1.8,-0.1],(-0.1,inf), per observation of the histogram|\n",
    "|cons.price.idx|quantile binning since this feature is highly multimodal|\n",
    "|cons.conf.idx|quantile binning since this feature is highly multimodal|\n",
    "|euribor3m|quantile binning since this feature is highly multimodal|\n",
    "|nr.employed|quantile binning since this feature is highly multimodal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:09:11.220115Z",
     "start_time": "2020-07-27T10:09:11.190195Z"
    }
   },
   "outputs": [],
   "source": [
    "# campaign\n",
    "value_map_campaign = lambda x: 'one' if x==1 else 'two' if x==2 else 'three' if x==3 else ' more than three'\n",
    "# pdays\n",
    "value_map_pdays = lambda x: 'never contacted' if x==999 else 'contacted'\n",
    "# previous\n",
    "value_map_previous = lambda x: 'never contacted' if x==0 else 'contacted'\n",
    "# emp.var.rate\n",
    "bin_map_emp = [-np.inf,-1.8,-0.1,np.inf]\n",
    "# cons.price.idex\n",
    "result,bins_cons_price = pd.cut(df_cat['cons.price.idx'],bins=3,right=True,retbins=True)\n",
    "bins_cons_price = np.round(bins_cons_price,3)\n",
    "# cons.conf.idx\n",
    "result,bins_cons_conf = pd.qcut(df_cat['cons.conf.idx'],q=5,retbins=True)\n",
    "bins_cons_conf = np.round(bins_cons_conf,3)\n",
    "# euribor3m\n",
    "results,bins_euribor = pd.qcut(df_cat['euribor3m'],q=5,retbins=True)\n",
    "bins_euribor = np.round(bins_euribor,3)\n",
    "# nr.employed\n",
    "results,bins_employed = pd.qcut(df_cat['nr.employed'],q=5,retbins=True,duplicates = 'drop')\n",
    "bins_employed = np.round(bins_employed,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also bin the 'age' column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_map_age = lambda x: '[18,30)' if x<30 else '[30,40)' if x<40 else '[40,50)' if x<50 else '[50,60)' if x<60 else '60+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:09:12.838788Z",
     "start_time": "2020-07-27T10:09:11.223107Z"
    }
   },
   "outputs": [],
   "source": [
    "# pipelines\n",
    "pipeline = pdp.MapColVals('campaign',value_map_campaign,drop=True)\n",
    "pipeline += pdp.MapColVals('pdays',value_map_pdays,drop=True)\n",
    "pipeline += pdp.MapColVals('previous',value_map_previous,drop=True)\n",
    "pipeline += pdp.Bin({'emp.var.rate':bin_map_emp[1:3]},drop=True)\n",
    "pipeline +=pdp.Bin({'cons.price.idx':bins_cons_price[1:5]},drop=True)\n",
    "pipeline +=pdp.Bin({'cons.conf.idx':bins_cons_conf[1:5]},drop=True)\n",
    "pipeline +=pdp.Bin({'euribor3m':bins_euribor[1:5]},drop=True)\n",
    "pipeline +=pdp.Bin({'nr.employed':bins_employed[1:5]},drop=True)\n",
    "pipeline +=pdp.MapColVals('age',value_map_age,drop=True)\n",
    "df_cat = pipeline(df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:09:12.875689Z",
     "start_time": "2020-07-27T10:09:12.840784Z"
    }
   },
   "outputs": [],
   "source": [
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:09:12.890650Z",
     "start_time": "2020-07-27T10:09:12.877685Z"
    }
   },
   "outputs": [],
   "source": [
    "#df_cat.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-27T10:09:19.152982Z",
     "start_time": "2020-07-27T10:09:12.892645Z"
    }
   },
   "outputs": [],
   "source": [
    "print('')\n",
    "print('Figure 5: Catgeorical Features vs Response Variable Summary')\n",
    "print('')\n",
    "print('Remark: the width of the bars in the ''Target proportions by Category (%)'' bar plot is proportional to the size of the classes in the dataset')\n",
    "print('')\n",
    "eda_cat_vs_target_binary(df_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['default'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "|Variables|Observations|\n",
    "|:---------|:-------|\n",
    "|`age`     |- Most of the clients are between 30 and 40 years old (41%), followed by clients with ages between 40 and 50 (25.62%). However, the clients that most subscribed a term deposit have ages above or equal to 60. It is however important to note that clients that are above 60 years old comprise only 2.91% of the observations (959 out of 32950); |\n",
    "|          |- This feature appears to impact the target.|\n",
    "|`job`      |- Most of the clients have jobs as admin (25.21%), blue-collar (22.66%) and technician (16.41%);|\n",
    "|         |- The job categories that subscribed the most to a term deposit are students (32.75%) and retired (25.04%). Note that students and retired clients make up only 2.08% and    0.83% respectively, of the observations. |\n",
    "|         |- This variable appears to impact the target.|\n",
    "|`marital`  |- The majority of the clients are married (60.61%), followed by single clients (about 28%);|\n",
    "|         |- The marital status does not appear to greatly affect the likelihood of a client to subscribe a term deposit;|\n",
    "|         \n",
    "|`education`|- Most of the clients have a university degree (29.4%), followed by clients with a high-school (23.17%) and basic.9y (14.72%);| \n",
    "|         |- The level 'illiterate' has only 0.04% of the observations, thus this level will be dropped;\n",
    "|         |- This variavel does not appear to impact the taget.|\n",
    "|`default`: has credit in default?  |- Only three clients have a credit in default.|\n",
    "|         |- It appears that clients with no credit in default are more likely to subscribe to a term deposit than the ones that didn't want to share that information;|\n",
    "|         |- This feature appears to impact the response.|\n",
    "|`Housing`: has housing loan?  |- The distribution of clients with a housing loan and without a housing loan are very similar, respectively 52.5% and 45.1%;|\n",
    "|         |- This features does not appear to impact the target.|\n",
    "|`loan`: has personal loan?     |- The majority of the clients do not have a personal loan (82.5%);|\n",
    "|         |- This feature does not appear to impact the target.|\n",
    "|`contact`  |- More than half of the clients were contacted via cellular (63.6%);|\n",
    "|         |- The clients that were contacted by cellular appear to be more likekely to subscribe to a term deposit (about 15%) compared to the clients that were contacted via telephone (about 5%), maybe because a client with cellular is more easy to be contacted;|\n",
    "|         |- This feature appears to impact the target.|\n",
    "|`month`   |- Most of the clients were contacted in May (33.45%), July (17.39%) and August (about 15%);|\n",
    "|         |- This feature appears to impact the target.|\n",
    "|`day_of_week`|- The distributions of the days of the week when the client was contacted does not vary much;|\n",
    "|           |- This feature does not appear to impact the target.| \n",
    "|`campaign`  |- Most of the clients were contacted one time (43.1%) and two times (25.6%);|\n",
    "|          |- The likelihood of the clients to describe a term deposit does not vary much between the number of contacts. For one contact 13% subscribed a term deposit, and for two contacts 11% subscribed a term deposit. Still not sure about the impact of this variable on the target.|\n",
    "|`pdays`: number of contacts performed during this campaign and for this client     |- Clients that were never contacted are about 93.4% of the observations. However the chances of subscribing a term deposit are much higher for clients that were recontacted (64%);|\n",
    "|          |- This feature appears to impact the target.|\n",
    "|`previous`: number of contacts performed before this campaign and for this client  |- 86.37% of the clinets were never contacted. And again, 27% of the clients that were contacted before this campaign subscribed to a term deposit in contrast to 9% of the never contacted clients that subscribed a term deposit;|\n",
    "|          |- This feature appears to impact the target.|\n",
    "|`poutcome`: outcome of the previous marketing campaign: outcome of the previous marketing campaign  |- Apparently most of the campaigns were just nonexistent (86.37%);|\n",
    "|                                                      |- Clearly, if the previous campaign was a success, the client will tend to subscribe again (about 66% did!);|\n",
    "|                                                      |- This feature appears to impact the target.|\n",
    "|`emp.var.rate`|- Although the great majority of the contacts was made when the 'emp.var.rate' was more than or equal to -0.1, the most subscribtions (39%) occured when the 'emp.var.rate' was less than -1.8;|\n",
    "|              |- This feature appears to impact the target.|\n",
    "|`cons.price.idx`|- Although the great majority of the contacts was made for a 'cons.price.idx' between 93.912-94.767, the most subscriptions occured for a 'cons.price.idx' less than 93.056;|\n",
    "|                |- This feature appears to impact the target.|\n",
    "|`cons.conf.idx`|- Most of the contacts were made when the 'cons.conf.idx' was less than or equal to -36.4 (37.8%), followed by when the 'cons.conf.idx' was between -46.2 and -42.0 (30.4%). However, most of the subscriptions occured when the 'cons.conf.idx' was between -40.0 and -36.4;|\n",
    "|               |- This feature appears to impact the target.|\n",
    "|`euribor3m`|-Most of the subscriptions occured when the 'euribor3m' was less than 1.299;|\n",
    "|           |- This feature appears to impact the target.|\n",
    "|`nr.employed`|- Most of the contacts were made when the 'nr.employed' was higher than or equal to 5228.1 (more people avaiable to make the phone calls?). Howerver most of the clients subscribed a term deposit when the 'nr.employed' was less than 5099.1 (less employees but more motivated? Fear of being fired?);|\n",
    "|             |- This feature appears to impact the target.|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above figures we can also see that there exists some classes named 'unknown'. Because this dataset is the result of phone calls, it is quite possible that some clients didn't want to answer some questions, therefore some (or all) of this missing values are not at random. In order to make a decision regarding imputation or deletion of the missing values, I will first calculate a contingency table of the features vs the response and calculate the chi squared stats as well as the p-value, to check for independe. In case, the features vs the response are dependent, we can't ignore it, and the missing values have to be imputed using the rest of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tab_chi_sqrt_p_value(df_cat,'unknown',df_cat['y'],0.99)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All values from the expected frequencies are above 5 which means that it's acceptable to use the chi-square.\n",
    "\n",
    "The only features that are dependent on the target are 'education' and 'default'. Regarding education, there are only 4.2% missing values so this feature will be imputed using the rest of the dataset. Regarding 'default', there are only 3 clients that subscribed a term deposit (figure 5), and there is quite a large amount of 'unknown' so imputation does not seem to me the right way to go, so I will keep the 'unknown' class. \n",
    "\n",
    "For the independent variables: \n",
    "- 'job': the class with the highest count is admin (25.21%) so I will add the 'unknown' to this category\n",
    "- 'marital': the class with the highest count is married (60.61%) so I will add the 'unknown' to this category\n",
    "- 'loan' : the class with the highest count is no (82.48%) so adding 2.4% of the 'unknown' here will hopefully not make a huge difference.\n",
    "- 'housing': in this one I will use the whole dataset to input the values since there is no big difference between no (45.10%) and yes (52.20%)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For now I will stop with EDA and move on to modelling (part II of this project can be found [here](./Bank-Marketing-Part-II-Modelling.ipynb)). \n",
    "<br>\n",
    "But first let's do a quick summary of the dataset:\n",
    "- The original dataset contains 41188 observations and 21 variables (10 numeric and 11 categorical);\n",
    "- Before EDA the dataset was splitted into training data and test data, and only the training data was analyzed. The split took into consideration the fact that the dataset was highly unbalanced (88.73% of the bank clients didn't subscribed a term deposit, while 11.27% did);\n",
    "- The feature 'duartion' was dropped before EDA due to data leakage;\n",
    "- There are 1227 (3.72%) duplicated rows. These duplicates were not removed, but I will test during modelling if by removing them will affect positively the result;\n",
    "- There were some outliers. However, the dataset is now completely categorical so no need to worry about those now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab2x",
   "language": "python",
   "name": "lab2x"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "213.416px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
